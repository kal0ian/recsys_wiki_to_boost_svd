{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import SVD\n",
    "from surprise import accuracy\n",
    "from surprise.reader import Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "USERS_COUNT = 943\n",
    "ITEMS_COUNT = 1682\n",
    "THRESHOLD = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = pd.DataFrame(Dataset.load_builtin(\"ml-100k\").raw_ratings)\n",
    "    data[0] = pd.to_numeric(data[0]) - 1\n",
    "    data[1] = pd.to_numeric(data[1]) - 1\n",
    "    del data[3]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_similarities():\n",
    "    similarities = pd.read_csv(\"artificial_ratings.csv\")\n",
    "    similarities['0'] = similarities['0'] - 1\n",
    "    similarities['1'] = similarities['1'] - 1\n",
    "\n",
    "    similarities_arr = np.zeros((ITEMS_COUNT, ITEMS_COUNT))\n",
    "    for _, row in similarities.iterrows():\n",
    "        if int(row['0']) != int(row['1']):\n",
    "            similarities_arr[int(row['0']), int(row['1'])] = row['2']\n",
    "        \n",
    "    return similarities_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data()\n",
    "similarities = load_similarities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 0.95\n",
      "Sparcitiy: 0.9968\n",
      "On Actual Train data\n",
      "RMSE: 0.7388\n",
      "On Actual Test data\n",
      "RMSE: 1.0541\n",
      "Calculating artificial ratings\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "RMSE: 1.1913\n",
      "Combined RMSE: 1.085\n",
      "\n",
      "Split: 0.80\n",
      "Sparcitiy: 0.9874\n",
      "On Actual Train data\n",
      "RMSE: 0.7184\n",
      "On Actual Test data\n",
      "RMSE: 1.0016\n",
      "Calculating artificial ratings\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "RMSE: 1.0687\n",
      "Combined RMSE: 1.013\n",
      "\n",
      "Split: 0.60\n",
      "Sparcitiy: 0.9748\n",
      "On Actual Train data\n",
      "RMSE: 0.7130\n",
      "On Actual Test data\n",
      "RMSE: 0.9599\n",
      "Calculating artificial ratings\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "RMSE: 1.0311\n",
      "Combined RMSE: 0.973\n",
      "\n",
      "Split: 0.40\n",
      "Sparcitiy: 0.9622\n",
      "On Actual Train data\n",
      "RMSE: 0.7065\n",
      "On Actual Test data\n",
      "RMSE: 0.9650\n",
      "Calculating artificial ratings\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "RMSE: 1.0284\n",
      "Combined RMSE: 0.975\n",
      "\n",
      "Split: 0.20\n",
      "Sparcitiy: 0.9496\n",
      "On Actual Train data\n",
      "RMSE: 0.6956\n",
      "On Actual Test data\n",
      "RMSE: 0.9525\n",
      "Calculating artificial ratings\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "RMSE: 1.0236\n",
      "Combined RMSE: 0.965\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "for split in [0.95, 0.80, 0.60, 0.40, 0.20]:\n",
    "    print(\"Split: %.2f\" % split)\n",
    "    train_set, _ = train_test_split(data, test_size=split)\n",
    "    sparcity = 1 - (len(train_set) / (USERS_COUNT * ITEMS_COUNT))\n",
    "    print(\"Sparcitiy: %.4f\" % sparcity)\n",
    "    train_set, test_set = train_test_split(train_set, test_size=.20)\n",
    "    \n",
    "    train_dataset = Dataset.load_from_df(train_set, reader=Reader())\n",
    "    \n",
    "    algo = SVD()\n",
    "    algo.fit(train_dataset.build_full_trainset())\n",
    "\n",
    "    print(\"On Actual Train data\")\n",
    "    predictions = algo.test(train_set.values)\n",
    "    accuracy.rmse(predictions)\n",
    "\n",
    "    print(\"On Actual Test data\")\n",
    "    predictions = algo.test(test_set.values)\n",
    "    accuracy.rmse(predictions)\n",
    "\n",
    "    actual = [prediction.r_ui for prediction in predictions]\n",
    "    est_actual = [prediction.est for prediction in predictions]\n",
    "    \n",
    "    print(\"Calculating artificial ratings\")\n",
    "    artificial = np.zeros((USERS_COUNT, ITEMS_COUNT))\n",
    "    for item in range(ITEMS_COUNT):\n",
    "        for user in range(USERS_COUNT):\n",
    "            rating = 0\n",
    "            all_user_ratings = train_set[train_set[0] == user]\n",
    "            sum_sim = 0\n",
    "            for _, row in all_user_ratings.iterrows():\n",
    "                sim1 = similarities[item, int(row[1])]\n",
    "                if (sim1 < threshold):\n",
    "                    continue\n",
    "                rating = rating + row[2] * sim1\n",
    "                sum_sim = sum_sim + sim1\n",
    "            if sum_sim == 0:\n",
    "                artificial[user, item] = -1\n",
    "            else:\n",
    "                artificial[user, item] = rating / sum_sim\n",
    "\n",
    "    dataframe = pd.DataFrame(columns=[0, 1, 2])\n",
    "    artificial_data = []\n",
    "    for item in range(ITEMS_COUNT):\n",
    "        for user in range(USERS_COUNT):\n",
    "            if (artificial[user, item] != -1):\n",
    "                artificial_data.append([user, item, artificial[user, item]])\n",
    "    artificial_dataset = pd.DataFrame(artificial_data)\n",
    "    artificial_train_dataset = Dataset.load_from_df(artificial_dataset, reader=Reader())\n",
    "    \n",
    "    algo = SVD(verbose=True)\n",
    "    algo.fit(artificial_train_dataset.build_full_trainset())\n",
    "\n",
    "    predictions = algo.test(test_set.values)\n",
    "    accuracy.rmse(predictions)\n",
    "\n",
    "    est_artificial = [x.est for x in predictions]\n",
    "\n",
    "    new_est = [(actual + artificial) / 2 for actual, artificial in zip(est_actual, est_artificial)]\n",
    "    \n",
    "    result[sparcity] = [math.sqrt(mean_squared_error(actual, new_est)),\n",
    "                       math.sqrt(mean_squared_error(actual, est_actual)),\n",
    "                       math.sqrt(mean_squared_error(actual, est_artificial))]\n",
    "    print(\"Combined RMSE: %.3f\" % math.sqrt(mean_squared_error(actual, new_est)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python\\python36\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other, axis)\u001b[0m\n\u001b[0;32m    877\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 879\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    880\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m                 raise TypeError('Could not compare {typ} type with Series'\n",
      "\u001b[1;32mc:\\program files\\python\\python36\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mna_op\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    814\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 816\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    817\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"invalid type comparison\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# for threshold in [0.8, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.05, 0.02, 0.01, 0.005]:\n",
    "for threshold in [0.05]:\n",
    "    result = np.zeros((USERS_COUNT, ITEMS_COUNT))\n",
    "    for item in range(ITEMS_COUNT):\n",
    "        for user in range(USERS_COUNT):\n",
    "            rating = 0\n",
    "            all_user_ratings = train_set[train_set[0] == user]\n",
    "            sum_sim = 0\n",
    "            for _, row in all_user_ratings.iterrows():\n",
    "                sim1 = similarities_arr[item, int(row[1])]\n",
    "                if (sim1 < threshold):\n",
    "                    continue\n",
    "                rating = rating + row[2] * sim1\n",
    "                sum_sim = sum_sim + sim1\n",
    "            if sum_sim == 0:\n",
    "                result[user, item] = -1\n",
    "            else:\n",
    "                result[user, item] = rating / sum_sim\n",
    "\n",
    "    dataframe = pd.DataFrame(columns=[0, 1, 2])\n",
    "    test = []\n",
    "    for item in range(ITEMS_COUNT):\n",
    "        for user in range(USERS_COUNT):\n",
    "            if (result[user, item] != -1):\n",
    "                test.append([user, item, result[user, item]])\n",
    "    artificial_dataset = pd.DataFrame(test)\n",
    "    artificial_train_dataset = Dataset.load_from_df(artificial_dataset, reader=Reader())\n",
    "    \n",
    "    algo = SVD(verbose=True)\n",
    "    algo.fit(artificial_train_dataset.build_full_trainset())\n",
    "    # predictions = algo.test(test_set)\n",
    "    # accuracy.rmse(predictions)\n",
    "\n",
    "\n",
    "    predictions = algo.test(test_set.values)\n",
    "    print(\"THRESHOLD: %.3f\" % threshold)\n",
    "    accuracy.rmse(predictions)\n",
    "    \n",
    "    est_artificial = [x.est for x in predictions]\n",
    "\n",
    "    new_est = [(actual + artificial) / 2 for actual, artificial in zip(est_actual, est_artificial)]\n",
    "    print(\"Combined RMSE: %.3f\" % math.sqrt(mean_squared_error(actual, new_est)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "RMSE: 1.0342\n",
      "Combined RMSE: 1.015\n",
      "\n"
     ]
    }
   ],
   "source": [
    "algo = SVD(verbose=True, biased=True)\n",
    "algo.fit(artificial_train_dataset.build_full_trainset())\n",
    "# predictions = algo.test(test_set)\n",
    "# accuracy.rmse(predictions)\n",
    "\n",
    "\n",
    "predictions = algo.test(test_set.values)\n",
    "accuracy.rmse(predictions)\n",
    "\n",
    "est_artificial = [x.est for x in predictions]\n",
    "\n",
    "new_est = [(actual + artificial) / 2 for actual, artificial in zip(est_actual, est_artificial)]\n",
    "print(\"Combined RMSE: %.3f\" % math.sqrt(mean_squared_error(actual, new_est)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.2904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2903710500767628"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = algo.test(test)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined RMSE: 1.090\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_est = [(actual + artificial) / 2 for actual, artificial in zip(est_actual, est_artificial)]\n",
    "print(\"Combined RMSE: %.3f\" % math.sqrt(mean_squared_error(actual, new_est)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53823"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(result == 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1149336"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(result != -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('artificial_ratings.out', result, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(columns=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for item in range(ITEMS_COUNT):\n",
    "    for user in range(USERS_COUNT):\n",
    "        if (result[user, item] != -1):\n",
    "            test.append([user, item, result[user, item]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "artificial_dataset = pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "artificial_train_dataset = Dataset.load_from_df(artificial_dataset, reader=Reader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_artificial = [x.est for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_actual = [x.est for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_est = [(actual + artificial) / 2 for actual, artificial in zip(est_actual, est_artificial)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = [x.r_ui for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.052369084226506"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(mean_squared_error(actual, new_est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 0\n",
      "epoch= 0 ; train error= 0.6741144397347321\n",
      "epoch= 1 ; train error= 0.5352607878468978\n",
      "epoch= 2 ; train error= 0.5237354856749674\n",
      "k= 1\n",
      "epoch= 0 ; train error= 0.5213615802595712\n",
      "epoch= 1 ; train error= 0.5166406387804316\n",
      "epoch= 2 ; train error= 0.5105357860276206\n",
      "epoch= 3 ; train error= 0.504803967573186\n",
      "epoch= 4 ; train error= 0.5010907963666331\n",
      "k= 2\n",
      "k= 3\n",
      "epoch= 0 ; train error= 0.4999686069454351\n",
      "k= 4\n",
      "k= 5\n",
      "k= 6\n",
      "epoch= 0 ; train error= 0.4987896712923216\n",
      "k= 7\n",
      "k= 8\n",
      "k= 9\n",
      "k= 10\n",
      "k= 11\n",
      "k= 12\n",
      "k= 13\n",
      "epoch= 0 ; train error= 0.497766722365444\n",
      "k= 14\n",
      "k= 15\n",
      "k= 16\n",
      "k= 17\n",
      "k= 18\n",
      "k= 19\n",
      "k= 20\n",
      "k= 21\n",
      "k= 22\n",
      "k= 23\n",
      "k= 24\n",
      "k= 25\n",
      "k= 26\n",
      "k= 27\n",
      "k= 28\n",
      "k= 29\n",
      "epoch= 0 ; train error= 0.49675714420205164\n",
      "k= 30\n",
      "k= 31\n",
      "k= 32\n",
      "k= 33\n",
      "k= 34\n",
      "k= 35\n",
      "k= 36\n",
      "k= 37\n",
      "k= 38\n",
      "k= 39\n",
      "k= 40\n",
      "k= 41\n",
      "k= 42\n",
      "k= 43\n",
      "k= 44\n",
      "k= 45\n",
      "k= 46\n",
      "k= 47\n",
      "k= 48\n",
      "k= 49\n",
      "k= 50\n",
      "k= 51\n",
      "k= 52\n",
      "k= 53\n",
      "k= 54\n",
      "k= 55\n",
      "k= 56\n",
      "k= 57\n",
      "k= 58\n",
      "k= 59\n",
      "k= 60\n",
      "k= 61\n",
      "k= 62\n",
      "k= 63\n",
      "k= 64\n",
      "k= 65\n",
      "k= 66\n",
      "k= 67\n",
      "k= 68\n",
      "k= 69\n",
      "k= 70\n",
      "k= 71\n",
      "k= 72\n",
      "k= 73\n",
      "k= 74\n",
      "k= 75\n",
      "k= 76\n",
      "k= 77\n",
      "k= 78\n",
      "k= 79\n",
      "k= 80\n",
      "k= 81\n",
      "k= 82\n",
      "k= 83\n",
      "k= 84\n",
      "k= 85\n",
      "k= 86\n",
      "k= 87\n",
      "k= 88\n",
      "k= 89\n",
      "k= 90\n",
      "k= 91\n",
      "k= 92\n",
      "k= 93\n",
      "k= 94\n",
      "k= 95\n",
      "k= 96\n",
      "k= 97\n",
      "k= 98\n",
      "k= 99\n",
      "rmsetrain:  0.49621590652801617\n",
      "rmsetest:  1.197993225609222\n",
      "time:  1300.41561293602\n"
     ]
    }
   ],
   "source": [
    "# Daniel Alabi and Cody Wang\n",
    "# ======================================\n",
    "# SvdMatrix:\n",
    "# generates matrices U and V such that\n",
    "# U * V^T closely approximates\n",
    "# the original matrix (in this case, the utility\n",
    "# matrix M)\n",
    "# =======================================\n",
    "\n",
    "\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "\n",
    "\"\"\"\n",
    "Rating class. \n",
    "Store every rating associated with a particular\n",
    "userid and movieid.\n",
    "================Optimization======================\n",
    "\"\"\"\n",
    "class Rating:\n",
    "    def __init__(self, userid, movieid, rating):\n",
    "        # to accomodate zero-indexing for matrices\n",
    "        self.uid = userid-1 \n",
    "        self.mid = movieid-1\n",
    "\n",
    "        self.rat = rating\n",
    "\n",
    "\n",
    "class SvdMatrix:\n",
    "    \"\"\"\n",
    "    trainfile -> name of file to train data against\n",
    "    nusers -> number of users in dataset\n",
    "    nmovies -> number of movies in dataset\n",
    "    r -> rank of approximation (for U and V)\n",
    "    lrate -> learning rate\n",
    "    regularizer -> regularizer\n",
    "    typefile -> 0 if for smaller MovieLens dataset\n",
    "                1 if for medium or larger MovieLens dataset\n",
    "    \"\"\"\n",
    "    def __init__(self, trainfile, nusers, nmovies, r=100, lrate=0.005, regularizer=0.1, typefile=0):\n",
    "        self.trainrats = []\n",
    "        self.testrats = []\n",
    "                \n",
    "        self.nusers = nusers\n",
    "        self.nmovies = nmovies\n",
    "\n",
    "        if typefile == 0:\n",
    "            self.readtrainsmaller(trainfile)\n",
    "        elif typefile == 1:\n",
    "            self.readtrainlarger(trainfile)\n",
    "\n",
    "        # get average rating\n",
    "        avg = self.averagerating()\n",
    "        # set initial values in U, V using square root\n",
    "        # of average/rank\n",
    "        initval = math.sqrt(avg/r)\n",
    "        \n",
    "        # U matrix\n",
    "        self.U = [[initval]*r for i in range(nusers)]\n",
    "        # V matrix -- easier to store and compute than V^T\n",
    "        self.V = [[initval]*r for i in range(nmovies)]\n",
    "\n",
    "        self.r = r\n",
    "        self.lrate = lrate\n",
    "        self.regularizer = regularizer\n",
    "        self.minimprov = 0.001\n",
    "        self.maxepochs = 5            \n",
    "\n",
    "    \"\"\"\n",
    "    Returns the dot product of v1 and v2\n",
    "    \"\"\"\n",
    "    def dotproduct(self, v1, v2):\n",
    "        return sum([v1[i]*v2[i] for i in range(len(v1))])\n",
    "\n",
    "    \"\"\"\n",
    "    Returns the estimated rating corresponding to userid for movieid\n",
    "    Ensures returns rating is in range [1,5]\n",
    "    \"\"\"\n",
    "    def calcrating(self, uid, mid):\n",
    "        p = self.dotproduct(self.U[uid], self.V[mid])\n",
    "        if p > 5:\n",
    "            p = 5\n",
    "        elif p < 1:\n",
    "            p = 1\n",
    "        return p\n",
    "\n",
    "    \"\"\"\n",
    "    Returns the average rating of the entire dataset\n",
    "    \"\"\"\n",
    "    def averagerating(self):\n",
    "        avg = 0\n",
    "        n = 0\n",
    "        for i in range(len(self.trainrats)):\n",
    "            avg += self.trainrats[i].rat\n",
    "            n += 1\n",
    "        return float(avg/n)\n",
    "\n",
    "    \"\"\"\n",
    "    Predicts the estimated rating for user with id i\n",
    "    for movie with id j\n",
    "    \"\"\"\n",
    "    def predict(self, i, j):\n",
    "        return self.calcrating(i, j)\n",
    "\n",
    "    \"\"\"\n",
    "    Trains the kth column in U and the kth row in\n",
    "    V^T\n",
    "    See docs for more details.\n",
    "    \"\"\"\n",
    "    def train(self, k):\n",
    "        sse = 0.0\n",
    "        n = 0\n",
    "        for i in range(len(self.trainrats)):\n",
    "            # get current rating\n",
    "            crating = self.trainrats[i]\n",
    "            err = crating.rat - self.predict(crating.uid, crating.mid)\n",
    "            sse += err**2\n",
    "            n += 1\n",
    "\n",
    "            uTemp = self.U[crating.uid][k]\n",
    "            vTemp = self.V[crating.mid][k]\n",
    "\n",
    "            self.U[crating.uid][k] += self.lrate * (err*vTemp - self.regularizer*uTemp)\n",
    "            self.V[crating.mid][k] += self.lrate * (err*uTemp - self.regularizer*vTemp)\n",
    "        return math.sqrt(sse/n)\n",
    "\n",
    "    \"\"\"\n",
    "    Trains the entire U matrix and the entire V (and V^T) matrix\n",
    "    \"\"\"\n",
    "    def trainratings(self):        \n",
    "        # stub -- initial train error\n",
    "        oldtrainerr = 1000000.0\n",
    "       \n",
    "        for k in range(self.r):\n",
    "            print(\"k=\", k)\n",
    "            for epoch in range(self.maxepochs):\n",
    "                trainerr = self.train(k)\n",
    "                \n",
    "                # check if train error is still changing\n",
    "                if abs(oldtrainerr-trainerr) < self.minimprov:\n",
    "                    break\n",
    "                oldtrainerr = trainerr\n",
    "                print(\"epoch=\", epoch, \"; train error=\", trainerr)\n",
    "                \n",
    "    \"\"\"\n",
    "    Calculates the RMSE using between arr\n",
    "    and the estimated values in (U * V^T)\n",
    "    \"\"\"\n",
    "    def calcrmse(self, arr):\n",
    "        nusers = self.nusers\n",
    "        nmovies = self.nmovies\n",
    "        sse = 0.0\n",
    "        total = 0\n",
    "        for i in range(len(arr)):\n",
    "            crating = arr[i]\n",
    "            sse += (crating.rat - self.calcrating(crating.uid, crating.mid))**2\n",
    "            total += 1\n",
    "        return math.sqrt(sse/total)\n",
    "\n",
    "    \"\"\"\n",
    "    Read in the ratings from fname and put in arr\n",
    "    Use splitter as delimiter in fname\n",
    "    \"\"\"\n",
    "    def readinratings(self, fname, arr, splitter=\"\\t\"):\n",
    "        f = open(fname)\n",
    "\n",
    "        for line in f:\n",
    "            newline = [int(float(each)) for each in line.split(splitter)]\n",
    "            userid, movieid, rating = newline[0], newline[1], newline[2]\n",
    "            arr.append(Rating(userid, movieid, rating))\n",
    "\n",
    "        arr = sorted(arr, key=lambda rating: (rating.uid, rating.mid))\n",
    "        return len(arr)\n",
    "        \n",
    "    \"\"\"\n",
    "    Read in the smaller train dataset\n",
    "    \"\"\"\n",
    "    def readtrainsmaller(self, fname):\n",
    "        return self.readinratings(fname, self.trainrats, splitter=\"\\t\")\n",
    "        \n",
    "    \"\"\"\n",
    "    Read in the large train dataset\n",
    "    \"\"\"\n",
    "    def readtrainlarger(self, fname):\n",
    "        return self.readinratings(fname, self.trainrats, splitter=\"::\")\n",
    "        \n",
    "    \"\"\"\n",
    "    Read in the smaller test dataset\n",
    "    \"\"\"\n",
    "    def readtestsmaller(self, fname):\n",
    "        return self.readinratings(fname, self.testrats, splitter=\"\\t\")\n",
    "                \n",
    "    \"\"\"\n",
    "    Read in the larger test dataset\n",
    "    \"\"\"\n",
    "    def readtestlarger(self, fname):\n",
    "        return self.readinratings(fname, self.testrats, splitter=\"::\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #========= test SvdMatrix class on smallest MovieLENS dataset =========\n",
    "    init = time.time()\n",
    "    svd = SvdMatrix(\"ua.base\", 943, 1682)\n",
    "    svd.trainratings()\n",
    "    print(\"rmsetrain: \", svd.calcrmse(svd.trainrats))\n",
    "    svd.readtestsmaller(\"ua.test\")\n",
    "    print(\"rmsetest: \", svd.calcrmse(svd.testrats))\n",
    "    print(\"time: \", time.time()-init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.0326087 , 0.04054054, ..., 0.        , 0.05454545,\n",
       "        0.01666667],\n",
       "       [0.0326087 , 0.        , 0.02702703, ..., 0.        , 0.01785714,\n",
       "        0.01694915],\n",
       "       [0.04054054, 0.02702703, 0.        , ..., 0.        , 0.05405405,\n",
       "        0.02439024],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.05454545, 0.01785714, 0.05405405, ..., 0.        , 0.        ,\n",
       "        0.0952381 ],\n",
       "       [0.01666667, 0.01694915, 0.02439024, ..., 0.        , 0.0952381 ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities_arr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
